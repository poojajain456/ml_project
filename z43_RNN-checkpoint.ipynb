{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de80f1a3",
   "metadata": {},
   "source": [
    "# RNN(Recurrent neural network)==>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1c4014",
   "metadata": {},
   "source": [
    "# Recurrent Neural Network and its applications =>\n",
    "\n",
    "Recurrent Neural Networks (RNNs) are a type of neural network designed to process sequential data by maintaining an internal state, or memory, to capture information from previous inputs. They are particularly useful when dealing with sequential and temporal data, as they can learn patterns and dependencies over time\n",
    "\n",
    "Here are some key reasons why RNNs are used:\n",
    "\n",
    "(1) Sequential Data Processing: RNNs excel at processing sequential data, where the order of elements matters, such as time series data, natural language\n",
    "\n",
    "processing (NLP), speech recognition, and handwriting recognition. They can capture dependencies between different elements in the sequence\n",
    "\n",
    "(2). Variable-Length Inputs: RNNs can handle variable-length inputs and produce corresponding outputs of the same sequence length. This flexibility is valuable in applications where inputs or outputs have varying lengths, such as text generation or speech synthesis.\n",
    "\n",
    "(3). Memory and Contextual information: RNNs maintain internal memory to store information about past inputs, allowing them to retain context and information from earlier elements in the sequence. This memory enables the network to make decisions based on previous inputs and their relationships.\n",
    "\n",
    "(4). Time Series Analysis RNNs are commonly used for analyzing time series data, such as financial data, weather data, and physiological signals. By considering the temporal nature of the data, RNNs can model trends, dependencies, and patterns over time.\n",
    "\n",
    "(5). Natural Language Processing (NLP): RNNs have proven to be highly effective in NLP tasks, including language modeling, machine translation, sentiment analysis, text classification, and named entity recognition. They can capture the semantic and syntactic structure of language by processing words or characters sequentially,\n",
    "\n",
    "(6). Speech Recognition and Generation: RNNs are extensively used in speech recognition systems to convert spoken language into written text. They can also be employed in speech synthesis applications, generating human-like speech from written text,\n",
    "\n",
    "(7) Image Captioning: RNNs can be combined with convolutional neural networks (CNNs) to generate descriptive captions for images. The CNN processes the image, and its output is fed into the RNN, which generates the corresponding caption\n",
    "\n",
    "(8) Video Analysis. RNNs are applicable to video analysis tasks, such as action recognition, video captioning, and video summarization. By considering the temporal dependencies between frames, RNNs can understand the temporal structure of videos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce964525",
   "metadata": {},
   "source": [
    "# What is Sequential Data ?\n",
    "\n",
    "Sequential data refers to a type of data where the order or sequence of elements carries significance and affects the interpretation or analysis of the data. In sequential data, the position or arrangement of elements conveys information or patterns that need to be captured and understood.\n",
    "\n",
    "Real-life examples of sequential data include:\n",
    "\n",
    "(1) Time Series Data. Time series data is a classic example of sequential data. It involves a sequence of data points recorded over time, where each point represents a measurement or observation taken at a specific time. Examples include stock prices, temperature recordings, heart rate monitoring, and daily sales data. The order of the data points is crucial for understanding trends, seasonality, and patterns over time\n",
    "\n",
    "(2). Natural Language Text: Textual data, such as sentences or paragraphs in natural language, is inherently sequential. The order of words and characters carries meaning and determines the semantics and syntax of the text. Language models, machine translation, sentiment analysis, and text generation tasks all rely on capturing the sequential structure of text.\n",
    "\n",
    "(3). Music and Audio Signals: Musical compositions and audio signals are sequential in nature. Musical notes played over time form a sequence that needs to be captured to understand melodies, rhythms, and harmonies, Similarly, audio signals like speech, music recordings, or environmental sounds can be \n",
    "\n",
    "(4). DNA Sequences: In genetics, DNA sequences represent the order of nucleotides (adenine, thymine, cytosine, and guanine) that make up an organism's genetic material, Analyzing and understanding DNA sequences is crucial in various biological applications, including genetic research, disease diagnosis, and evolutionary studies.\n",
    "\n",
    "(5) User Behavior Data:- Sequential data can also be found in user behaviour logs, such as web clickstreams or transaction histories . the order of action taken by user provides insights into their browsing patterns, preference or purchasing behaviours. Analzying this sequential data can help optimize.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbb9924",
   "metadata": {},
   "source": [
    "# RNN forward propagation with time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8c628be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: [ 1.69688019 -2.04029544]\n",
      "Output: [ 1.73621062 -1.92409437]\n",
      "Output: [ 1.68592965 -2.07397626]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the RNN parameters\n",
    "input_size = 4  # Dimensionality of the input at each time step\n",
    "hidden_size = 3  # Dimensionality of the hidden state\n",
    "output_size = 2  # Dimensionality of the output at each time step\n",
    "\n",
    "# Define the input sequence\n",
    "sequence = np.array([[1, 2, 3, 4],\n",
    "                     [5, 6, 7, 8],\n",
    "                     [9, 10, 11, 12]])\n",
    "\n",
    "# Initialize the RNN weights\n",
    "Wxh = np.random.randn(hidden_size, input_size)  # Weight matrix for input-to-hidden connections\n",
    "Whh = np.random.randn(hidden_size, hidden_size)  # Weight matrix for hidden-to-hidden connections\n",
    "Why = np.random.randn(output_size, hidden_size)  # Weight matrix for hidden-to-output connections\n",
    "bh = np.zeros((hidden_size, 1))  # Bias for hidden state\n",
    "by = np.zeros((output_size, 1))  # Bias for output\n",
    "\n",
    "# Initialize the hidden state\n",
    "h_prev = np.zeros((hidden_size, 1))\n",
    "\n",
    "# Perform forward propagation through time\n",
    "for x in sequence:\n",
    "    # Convert input to column vector\n",
    "    x = x.reshape(-1, 1)\n",
    "    \n",
    "    # Calculate the hidden state\n",
    "    h = np.tanh(np.dot(Wxh, x) + np.dot(Whh, h_prev) + bh)\n",
    "    \n",
    "    # Calculate the output\n",
    "    y = np.dot(Why, h) + by\n",
    "    \n",
    "    # Print the output at each time step\n",
    "    print(\"Output:\", y.ravel())\n",
    "    \n",
    "    # Update the hidden state for the next time step\n",
    "    h_prev = h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f00db9d",
   "metadata": {},
   "source": [
    "# example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5ef8b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd976ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the RNN model\n",
    "rnn=tf.keras.layers.SimpleRNN(units=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d68d246",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the loss function\n",
    "loss_fn=tf.keras.losses.MeanSquaredError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26358755",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the optimizer\n",
    "optimizer=tf.keras.optimizers.SGD(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb0281a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate dummy data\n",
    "input_data=tf.random.normal(shape=(32,10,32))\n",
    "target_data=tf.random.normal(shape=(32,64))   #adjut the shape to match predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c09201d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform forward pass\n",
    "with tf.GradientTape() as tape:\n",
    "    predictions=rnn(input_data)\n",
    "    loss_value=loss_fn(target_data, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a943b8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform backward pass \n",
    "gradients = tape.gradient(loss_value, rnn.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c30ba65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=() dtype=int64, numpy=1>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Update parameters \n",
    "optimizer.apply_gradients (zip(gradients, rnn.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36293200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(32, 64), dtype=float32, numpy=\n",
       " array([[-0.00688076,  0.00873566, -0.00395154, ..., -0.0040577 ,\n",
       "         -0.00454749,  0.0067466 ],\n",
       "        [-0.00459323,  0.00349588, -0.00800731, ..., -0.00431118,\n",
       "          0.00143406,  0.00627496],\n",
       "        [-0.00528306,  0.00473082,  0.00788249, ..., -0.00033832,\n",
       "         -0.00472271,  0.0017578 ],\n",
       "        ...,\n",
       "        [ 0.00152863,  0.00090326,  0.00835702, ..., -0.00140617,\n",
       "         -0.00150383, -0.00152733],\n",
       "        [-0.00356281, -0.01438114, -0.00433497, ...,  0.00080661,\n",
       "          0.00628009, -0.01429786],\n",
       "        [-0.0021537 ,  0.00075253, -0.00308939, ..., -0.00172399,\n",
       "          0.00400855,  0.0083855 ]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(64, 64), dtype=float32, numpy=\n",
       " array([[ 0.00162759,  0.00070198,  0.002503  , ...,  0.00248234,\n",
       "          0.00307477, -0.00143002],\n",
       "        [ 0.00187489, -0.00420337, -0.00256418, ...,  0.00443938,\n",
       "         -0.00416736, -0.00206547],\n",
       "        [-0.00680521,  0.00138297,  0.00083526, ..., -0.00076697,\n",
       "          0.00668283, -0.00243888],\n",
       "        ...,\n",
       "        [-0.00022258,  0.00302254,  0.00111425, ..., -0.0014903 ,\n",
       "         -0.00137822,  0.00605446],\n",
       "        [-0.0058074 , -0.00028291, -0.00287832, ..., -0.0055016 ,\n",
       "         -0.00075534, -0.00430204],\n",
       "        [ 0.00212587, -0.00271211, -0.00543959, ...,  0.00398084,\n",
       "          0.00161718, -0.00890579]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(64,), dtype=float32, numpy=\n",
       " array([ 0.00291758,  0.00570117, -0.0008471 ,  0.000571  ,  0.00417646,\n",
       "        -0.00092144, -0.01007127, -0.0055109 , -0.00442664,  0.00445099,\n",
       "         0.0006306 ,  0.00165556, -0.00192011,  0.00032945,  0.00522493,\n",
       "         0.000918  , -0.00601431,  0.00535692,  0.00174072,  0.00366577,\n",
       "         0.00317234, -0.00513256,  0.005141  ,  0.00607946,  0.00296676,\n",
       "        -0.00142769, -0.01267809,  0.0040131 , -0.0008884 ,  0.00455992,\n",
       "         0.00313991,  0.00486241,  0.00057208, -0.00491146,  0.00570511,\n",
       "        -0.00327681, -0.00391678,  0.00954639, -0.00147102,  0.00611134,\n",
       "        -0.00187111,  0.00127486,  0.00438031, -0.00425295,  0.00204419,\n",
       "         0.00050681, -0.011638  , -0.00126866, -0.00395233, -0.00253717,\n",
       "         0.01012207,  0.00017556, -0.00363634,  0.01033671,  0.00321108,\n",
       "        -0.00214469,  0.00170235, -0.00425279,  0.00109936, -0.00687649,\n",
       "         0.00237493, -0.00230454, -0.00057304,  0.00751586], dtype=float32)>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd9f478",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
